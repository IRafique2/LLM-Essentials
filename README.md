# LLM-Essentials


## Overview

**LLM Essentials** is a structured learning repository designed to **teach learners about Large Language Models (LLMs)**. The goal is to provide a concise, clear, and progressive pathway from foundational concepts to practical applications.

---

## Learning Objectives

By following this repository, learners will:

* Understand the evolution from AI and ML to LLMs
* Learn core concepts like language modeling, tokenization, embeddings, and transformers
* Explore how LLMs are trained, fine-tuned, and evaluated
* Gain hands-on experience with basic experiments and prompt engineering

---

## Topics Covered

The content progresses through the following topics (exact details will be added day by day):

* Introduction and foundational concepts
* Statistical models & n-grams
* Recurrent Neural Networks (RNN), LSTM, GRU
* Transformers and attention mechanisms
* Shift in architecture and capabilities
* Pretraining and fine-tuning LLMs
* LLM tasks and evaluation
* LLM scaling laws
* Small vs large language models
* Mixture of Experts (MoE) and agent-based models

---

## Repository Structure

```
LLM_Essentials/
│
├── README.md               # Overview and guide
├── docs/                   # Theory notes for each topic
├── diagrams/               # Visual explanations
├── experiments/            # Hands-on notebooks and demos
├── prompts/                # Prompting examples and exercises
└── references/             # Key papers, blogs, and resources
```

---


## Status

 **Work in Progress**
Content will be added progressively as part of the learning plan.

---

## Author
Isra Rafique

